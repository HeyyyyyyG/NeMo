trainer:
  devices: 1
  num_nodes: 1
  accelerator: gpu
  logger: False # logger provided by exp_manager
  precision: 16 # 16, 32, or bf16

data:
  test_ds: ["data/financial_phrase_bank_test_ground_truth.jsonl"]
  num_workers: 1
  batch_size: 16
  
tensor_model_parallel_size: 1
pipeline_model_parallel_size: 1
pipeline_model_parallel_split_rank: 0 # used for encoder and decoder model
t5_model_file: "models/megatron_t5_220m_f16.nemo"  # T5 nemo file path
virtual_prompt_model_file: "models/p_tuning_sent_t5.nemo" # path to a MegatronT5PromptLearningModel model 
checkpoint_dir: null # checkpoint file dir. This is used to load the PTL checkpoint generated during the T5 training
checkpoint_name: null # PTL checkpoint file name, only used for PTL checkpoint loading
hparams_file: null # model configuration file, only used for PTL checkpoint loading

